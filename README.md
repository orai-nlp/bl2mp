# How Well Can BERT Learn the Grammar of an Agglutinative and Flexible-Order Language? The Case of Basque.

Data (corpora and BL2MP dataset), models and evaluation scripts from our work [*How Well Can BERT Learn the Grammar of an Agglutinative and Flexible-Order Language? The Case of Basque.*]() accepted at LREC-COLING2024.

*Soon Available*

*BL2MP will be available on HuggingFace too*

Authors
-----------
Gorka Urbizu [1] [2], Muitze Zulaika [1], Xabier Saralegi [1], Ander Corral [1]

Affiliation of the authors: 

[1] Orai NLP Technologies

[2] University of the Basque Country



Licensing
-------------

Copyright (C) by Orai NLP Technologies. 

The corpora, datasets and models created in this work, are licensed under the Creative Commons Attribution-ShareAlike 4.0.

International License (CC BY-SA 4.0). To view a copy of this license, visit [http://creativecommons.org/licenses/by-sa/4.0/](https://creativecommons.org/licenses/by-sa/4.0/).



Acknowledgements
-------------------
If you use these corpora, datasets or models please cite the following paper:

- G. Urbizu, M. Zulaika, X. Saralegi, A. Corral. How Well Can BERT Learn the Grammar of an Agglutinative and Flexible-Order Language? The Case of Basque. The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING2024). May, 2024. Torino, Italia



Contact information
-----------------------
Gorka Urbizu, Muitze Zulaika: {g.urbizu,m.zulaika}@orai.eus